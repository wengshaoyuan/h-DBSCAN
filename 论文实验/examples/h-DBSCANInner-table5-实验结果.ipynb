{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74332c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is dataset of  dataSet/datasetWithnoTarget/AGGREGATION.csv  the running time is 0.186887  the eps is  1.5  the min_pts is  6\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/t4.8k.csv  the running time is 9.928002  the eps is  8.5  the min_pts is  15\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/D31.csv  the running time is 2.054953  the eps is  0.8  the min_pts is  30\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/iris.csv  the running time is 0.021938  the eps is  0.4  the min_pts is  9\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/HTRU_2.csv  the running time is 50.099738  the eps is  0.3  the min_pts is  15\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/ecoli.csv  the running time is 1.158742  the eps is  0.8  the min_pts is  30\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/digits.csv  the running time is 0.498692  the eps is  8.5  the min_pts is  15\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/3dSRN3D.csv  the running time is 14.340012  the eps is  0.1  the min_pts is  20\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/household.csv  the running time is 158.400832  the eps is  1  the min_pts is  40\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/HIGGS13D.csv  the running time is 18.044378  the eps is  2  the min_pts is  5\n",
      "--------------\n",
      "this is dataset of  dataSet/datasetWithnoTarget/HIGGS28D.csv  the running time is 0.46045  the eps is  2.4  the min_pts is  5\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "#the resulet in dataset of ecoli\n",
    "import hnswlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import hnswlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import tracemalloc\n",
    "import datetime\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    y_voted_labels = np.zeros(y_true.shape)\n",
    "    labels = np.unique(y_true)\n",
    "    ordered_labels = np.arange(labels.shape[0])\n",
    "    for k in range(labels.shape[0]):\n",
    "        y_true[y_true==labels[k]] = ordered_labels[k]\n",
    "    labels = np.unique(y_true)\n",
    "    bins = np.concatenate((labels, [np.max(labels)+1]), axis=0)\n",
    "    for cluster in np.unique(y_pred):\n",
    "        hist, _ = np.histogram(y_true[y_pred==cluster], bins=bins)\n",
    "        winner = np.argmax(hist)\n",
    "        y_voted_labels[y_pred==cluster] = winner\n",
    "\n",
    "    return accuracy_score(y_true, y_voted_labels)\n",
    "\n",
    "def hnswlibTok(data):                  #使用HNSW查找每个数据点的最近邻\n",
    "    dim = len(data[0])\n",
    "    data_lables=range(len(data))\n",
    "    p = hnswlib.Index(space='l2', dim=dim)\n",
    "    p.init_index(max_elements=len(data), ef_construction=200, M=20)\n",
    "    p.add_items(data,data_lables)\n",
    "    p.set_ef(50)\n",
    "    labels,distance = p.knn_query(data, k=len(data))       #len(X)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def findNeighbor(labels,data,eps):\n",
    "    innerMC=[]\n",
    "    neighbor = []\n",
    "    dictss=[]\n",
    "    centers=data[labels[0]]\n",
    "    for curr in range(0, len(labels)):\n",
    "        currData=data[labels[curr]]\n",
    "\n",
    "        dist = np.sqrt(np.sum(np.square(centers - currData)))\n",
    "        dictss.append(dist)\n",
    "        if dist<0.5*eps:\n",
    "            innerMC.append(labels[curr])\n",
    "        if dist > eps:  # 找到小于半径的截至索引位置\n",
    "            neighbor = labels[0:curr]\n",
    "            break\n",
    "    return neighbor,innerMC\n",
    "\n",
    "def asignLable(data,eps,min_Pts):                  #使用HNSW查找每个数据点的最近邻\n",
    "    rangeQuire=hnswlibTok(data)\n",
    "    emptyPoinnt=[]\n",
    "    data_label = list(range(len(data)))\n",
    "    core = []\n",
    "    neighbor_dict = {}\n",
    "    noise=[]\n",
    "\n",
    "    while len(data_label) != 0:\n",
    "        center = data_label[0]\n",
    "        data_label.remove(center)  # 把查询点删除了。\n",
    "        lable=rangeQuire[center]\n",
    "\n",
    "        neighbor,innerMC = findNeighbor(lable, data, eps)\n",
    "        if len(neighbor) >=min_Pts:\n",
    "            core.append(center)\n",
    "\n",
    "            # 在内环的邻居数大于密度阈值时，才进行查询。\n",
    "            if len(innerMC)>min_Pts+1:\n",
    "                core=core+innerMC\n",
    "                for i in innerMC:\n",
    "                    if i not in neighbor_dict.keys():\n",
    "                        neighbor_dict[i]=[]\n",
    "        if len(neighbor)==0:    #判断此点是否为空值点\n",
    "            noise.append(center)\n",
    "        neighbor_dict[center] = neighbor\n",
    "    core = set(core)\n",
    "    noise=set(noise)\n",
    "    return neighbor_dict,core,noise\n",
    "\n",
    "def DBSCAN(X, eps, min_Pts):\n",
    "    k = -1          #初始化聚类簇数 k=-1\n",
    "    gama = set([x for x in range(len(X))])  # 初始化未访问样本集合：gama\n",
    "    cluster = [-1 for _ in range(len(X))]  # 聚类\n",
    "    neighbor_list,omega_list,noise=asignLable(X,eps,min_Pts)\n",
    "\n",
    "\n",
    "    while len(omega_list) > 0:\n",
    "        gama_old = copy.deepcopy(gama)\n",
    "        j = random.choice(list(omega_list))  # 随机选取一个核心对象\n",
    "        k = k + 1\n",
    "        Q = list()\n",
    "        Q.append(j)\n",
    "        gama.remove(j)\n",
    "        while len(Q) > 0:\n",
    "            q = Q[0]\n",
    "            Q.remove(q)\n",
    "            if len(neighbor_list[q]) >= min_Pts:\n",
    "            # if q  in list(omega_list):\n",
    "                delta = set(neighbor_list[q]) & gama\n",
    "                deltalist = list(delta)\n",
    "                for i in range(len(delta)):\n",
    "                    Q.append(deltalist[i])\n",
    "                    gama = gama - delta\n",
    "        Ck = gama_old - gama\n",
    "        Cklist = list(Ck)\n",
    "        for i in range(len(Ck)):\n",
    "            cluster[Cklist[i]] = k\n",
    "        omega_list = omega_list - Ck\n",
    "    gama=gama-noise\n",
    "    for i in gama:\n",
    "        neihbor_noise=neighbor_list[i]\n",
    "        number = set(neihbor_noise).intersection(omega_list)\n",
    "        if len(number)==0:\n",
    "            continue\n",
    "        if len(number)!=0:\n",
    "            cluster[i]=cluster[list(number)[0]]\n",
    "    return cluster\n",
    "if __name__ == '__main__':\n",
    "    fileSet=[\"dataSet/datasetWithnoTarget/AGGREGATION.csv\",\n",
    "             \"dataSet/datasetWithnoTarget/t4.8k.csv\",\n",
    "             \"dataSet/datasetWithnoTarget/D31.csv\",\n",
    "             \"dataSet/datasetWithnoTarget/iris.csv\"\n",
    "             ,\"dataSet/datasetWithnoTarget/HTRU_2.csv\"\n",
    "            ,\"dataSet/datasetWithnoTarget/ecoli.csv\"\n",
    "              ,\"dataSet/datasetWithnoTarget/digits.csv\"\n",
    "            ,\"dataSet/datasetWithnoTarget/3dSRN3D.csv\"\n",
    "            ,\"dataSet/datasetWithnoTarget/household.csv\"\n",
    "            ,\"dataSet/datasetWithnoTarget/HIGGS13D.csv\"\n",
    "            ,\"dataSet/datasetWithnoTarget/HIGGS28D.csv\"]\n",
    "    \n",
    "    min_Pts_list=[6,15,30,9,15,30,15,20,40,5,5]\n",
    "    eps_list=    [1.5,8.5,0.8,0.4,0.3,0.8,8.5,0.1,1,2,2.4]\n",
    "    for i in range(len(eps_list)):\n",
    "#         for i in range(len(eps_list)):\n",
    "        data_withlabels = pd.read_csv(fileSet[i],header=None)\n",
    "        data = (data_withlabels).values\n",
    "        df_data = pd.DataFrame(data)\n",
    "        data=np.array(data)\n",
    "\n",
    "\n",
    "\n",
    "        currentPeakMemory=[]\n",
    "        PeakMemory=[]\n",
    "\n",
    "        begin = datetime.datetime.now()\n",
    "\n",
    "        C = DBSCAN(data, eps_list[i], min_Pts_list[i])\n",
    "\n",
    "        end = datetime.datetime.now()\n",
    "\n",
    "        totalTime = (end - begin).total_seconds()\n",
    "        print(\"this is dataset of \",fileSet[i],\" the running time is\",totalTime,\" the eps is \",eps_list[i],\" the min_pts is \",min_Pts_list[i])\n",
    "\n",
    "        print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf11d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
